{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0955a5f-aaa4-48e9-b622-9372974a4b80",
   "metadata": {},
   "source": [
    "On cherche à réecrire le checkpoint pth de SAM pour être \"conforme\" à lightning, i.e avec les clés attendues dans le dictionnaire de state_dict.\n",
    "\n",
    "L'erreur initiale est : `KeyError: 'pytorch-lightning_version'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b134c7-9a4a-4a77-baec-402c4fcb9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import torch\n",
    "from src.commons.constants import PROJECT_PATH\n",
    "from omegaconf import DictConfig, OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ec6ccc-33e1-4f1a-8abd-86d203301d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcallbacks\u001b[0m/  eval.yaml    \u001b[01;34mhparams_search\u001b[0m/  \u001b[01;34mlocal\u001b[0m/    \u001b[01;34mmodel\u001b[0m/     \u001b[01;34mtrainer\u001b[0m/\n",
      "\u001b[01;34mdata\u001b[0m/       \u001b[01;34mexperiment\u001b[0m/  \u001b[01;34mhydra\u001b[0m/           \u001b[01;34mlogger\u001b[0m/   \u001b[01;34mpaths\u001b[0m/     train.yaml\n",
      "\u001b[01;34mdebug\u001b[0m/      \u001b[01;34mextras\u001b[0m/      __init__.py      \u001b[01;34mmetrics\u001b[0m/  \u001b[01;34msam_type\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls ../../configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de33b054-2e05-496d-ad17-07145c417021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    # Initialize the Hydra configuration\n",
    "    hydra.initialize(config_path=\"../../configs\", version_base=None)\n",
    "    \n",
    "    # Compose the configuration with the desired environment override\n",
    "    cfg = hydra.compose(config_name=\"train\", overrides=[\"experiment=mp_naive\", \"sam_type=small\", \"data=levir-cd\"])\n",
    "    \n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f1b5420-83c4-4055-96a7-757e1f761660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "  name: levir-cd\n",
      "  _target_: src.data.datamodule.CDDataModule\n",
      "  params:\n",
      "    prompt_type: sample\n",
      "    n_prompt: 1\n",
      "    loc: center\n",
      "    batch_size: 2\n",
      "    n_shape: null\n",
      "    num_worker: 8\n",
      "model:\n",
      "  network:\n",
      "    image_encoder:\n",
      "      _target_: src.models.segment_anything.modeling.image_encoder_dev.ImageEncoderViT\n",
      "      depth: 12\n",
      "      embed_dim: 768\n",
      "      img_size: 1024\n",
      "      mlp_ratio: 4\n",
      "      norm_layer: null\n",
      "      num_heads: 12\n",
      "      patch_size: 16\n",
      "      qkv_bias: true\n",
      "      use_rel_pos: true\n",
      "      global_attn_indexes:\n",
      "      - 2\n",
      "      - 5\n",
      "      - 8\n",
      "      - 11\n",
      "      window_size: 14\n",
      "      out_chans: 256\n",
      "    prompt_encoder:\n",
      "      _target_: src.models.segment_anything.modeling.prompt_encoder_dev.PromptEncoder\n",
      "      embed_dim: 256\n",
      "      image_embedding_size:\n",
      "      - 64\n",
      "      - 64\n",
      "      input_image_size:\n",
      "      - 1024\n",
      "      - 1024\n",
      "      mask_in_chans: 16\n",
      "    mask_decoder:\n",
      "      transformer:\n",
      "        _target_: src.models.segment_anything.modeling.transformer_dev.TwoWayTransformer\n",
      "        depth: 2\n",
      "        embedding_dim: 256\n",
      "        mlp_dim: 2048\n",
      "        num_heads: 8\n",
      "      _target_: src.models.segment_anything.modeling.mask_decoder_dev.MaskDecoder\n",
      "      num_multimask_outputs: 3\n",
      "      transformer_dim: 256\n",
      "      iou_head_depth: 3\n",
      "      iou_head_hidden_dim: 256\n",
      "    _target_: src.models.magic_pen.bisam_diff.BiSamDiff\n",
      "  instance:\n",
      "    _target_: src.models.magic_pen.task.MagicPenModule\n",
      "    network: ${model.network}\n",
      "    params: null\n",
      "sam_name: small\n",
      "sam_ckpt_path: ${paths.sam_ckpt_dir}/sam_vit_b_01ec64.pth\n",
      "sam_enc_arch: vit-b\n",
      "tags:\n",
      "- dev\n",
      "callbacks:\n",
      "  model_checkpoint:\n",
      "    _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: epoch_{epoch:03d}\n",
      "    monitor: val/loss\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 1\n",
      "    mode: min\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  rich_progress_bar:\n",
      "    _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "logger:\n",
      "  tensorboard:\n",
      "    _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger\n",
      "    save_dir: ${paths.output_dir}/tensorboard/\n",
      "    name: null\n",
      "    default_hp_metric: false\n",
      "trainer:\n",
      "  _target_: lightning.pytorch.trainer.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 1\n",
      "  max_epochs: 10\n",
      "  accelerator: cpu\n",
      "  devices: 1\n",
      "  check_val_every_n_epoch: 1\n",
      "  deterministic: false\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_PATH}\n",
      "  data_dir: ${oc.env:DATA_PATH}\n",
      "  log_dir: ${oc.env:LOGS_PATH}\n",
      "  output_dir: ${hydra:runtime.output_dir}\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "  sam_ckpt_dir: ${oc.env:CHECKPOINTS_PATH}/sam\n",
      "extras:\n",
      "  ignore_warnings: false\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "task_name: overfit_sample\n",
      "train: true\n",
      "test: true\n",
      "ckpt_path: null\n",
      "seed: 66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hydra.core.global_hydra import GlobalHydra\n",
    "GlobalHydra.instance().clear()\n",
    "cfg = load_config()\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a39bbe16-631b-41d7-986a-3128d9f36cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = hydra.utils.instantiate(cfg.model.instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58a9eb68-c6cf-4dd1-91d9-e06a373c2962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/var/data/usr/mdizier/stylo_magique/checkpoints/sam/sam_vit_b_01ec64.pth\"\n",
    "module.model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c24ffc-cd4e-4168-91bc-8405bf2a5afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
