{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc72f73-bdab-442d-b189-a08e1dff256a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f300772-a188-4544-89ca-54ec89a8fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from src.commons.constants import PROJECT_PATH\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Metric\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from src.commons.utils_io import load_sam, make_path\n",
    "from src.commons.utils import to_numpy, SegAnyChangeVersion, show_img, show_pair_img, show_prediction_sample, resize\n",
    "from src.models.commons.mask_process import extract_object_from_batch, binarize_mask\n",
    "from src.commons.constants import *\n",
    "from src.data.process import generate_grid_prompt\n",
    "from src.commons.utils import create_sample_grid_with_prompt, get_mask_with_prompt, fig2arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f7e75-e6da-447c-88b7-b197c9fa2f37",
   "metadata": {},
   "source": [
    "### Load config for run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f57dad-7cbf-4fbc-8804-e39ae76613cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    # Initialize the Hydra configuration\n",
    "    hydra.initialize(config_path=\"../configs\", version_base=None)\n",
    "    \n",
    "    # Compose the configuration with the desired environment override\n",
    "    cfg = hydra.compose(config_name=\"train\", overrides=[\"experiment=probing_diff\", \"sam_type=small\", \"data=levir-cd\"])\n",
    "    \n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f10476-a0ce-47fc-aa6b-53a6c447fdfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "  name: levir-cd\n",
      "  _target_: src.data.datamodule.CDDataModule\n",
      "  params:\n",
      "    prompt_type: sample\n",
      "    n_prompt: 1\n",
      "    loc: center\n",
      "    batch_size: 2\n",
      "    num_worker: 4\n",
      "    pin_memory: false\n",
      "    n_shape: 3\n",
      "model:\n",
      "  network:\n",
      "    image_encoder:\n",
      "      _target_: src.models.segment_anything.modeling.image_encoder_dev.ImageEncoderViT\n",
      "      depth: 12\n",
      "      embed_dim: 768\n",
      "      img_size: 1024\n",
      "      mlp_ratio: 4\n",
      "      norm_layer: null\n",
      "      num_heads: 12\n",
      "      patch_size: 16\n",
      "      qkv_bias: true\n",
      "      use_rel_pos: true\n",
      "      global_attn_indexes:\n",
      "      - 2\n",
      "      - 5\n",
      "      - 8\n",
      "      - 11\n",
      "      window_size: 14\n",
      "      out_chans: 256\n",
      "    prompt_encoder:\n",
      "      _target_: src.models.segment_anything.modeling.prompt_encoder_dev.PromptEncoder\n",
      "      embed_dim: 256\n",
      "      image_embedding_size:\n",
      "      - 64\n",
      "      - 64\n",
      "      input_image_size:\n",
      "      - 1024\n",
      "      - 1024\n",
      "      mask_in_chans: 16\n",
      "    mask_decoder:\n",
      "      transformer:\n",
      "        _target_: src.models.segment_anything.modeling.transformer_dev.TwoWayTransformer\n",
      "        depth: 2\n",
      "        embedding_dim: 256\n",
      "        mlp_dim: 2048\n",
      "        num_heads: 8\n",
      "      _target_: src.models.segment_anything.modeling.mask_decoder_dev.MaskDecoder\n",
      "      num_multimask_outputs: 3\n",
      "      transformer_dim: 256\n",
      "      iou_head_depth: 3\n",
      "      iou_head_hidden_dim: 256\n",
      "    _target_: src.models.magic_pen.bisam_diff.BiSamDiff\n",
      "    params:\n",
      "      sam_ckpt_path: ??\n",
      "      use_weights:\n",
      "      - image_encoder\n",
      "      ft_mode: ??\n",
      "  optimizer:\n",
      "    _target_: torch.optim.Adam\n",
      "    _partial_: true\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0.0\n",
      "  scheduler:\n",
      "    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau\n",
      "    _partial_: true\n",
      "    mode: min\n",
      "    factor: 0.3\n",
      "    patience: 10\n",
      "  instance:\n",
      "    _target_: src.models.magic_pen.task.MagicPenModule\n",
      "    network:\n",
      "      image_encoder:\n",
      "        _target_: src.models.segment_anything.modeling.image_encoder_dev.ImageEncoderViT\n",
      "        depth: 12\n",
      "        embed_dim: 768\n",
      "        img_size: 1024\n",
      "        mlp_ratio: 4\n",
      "        norm_layer: null\n",
      "        num_heads: 12\n",
      "        patch_size: 16\n",
      "        qkv_bias: true\n",
      "        use_rel_pos: true\n",
      "        global_attn_indexes:\n",
      "        - 2\n",
      "        - 5\n",
      "        - 8\n",
      "        - 11\n",
      "        window_size: 14\n",
      "        out_chans: 256\n",
      "      prompt_encoder:\n",
      "        _target_: src.models.segment_anything.modeling.prompt_encoder_dev.PromptEncoder\n",
      "        embed_dim: 256\n",
      "        image_embedding_size:\n",
      "        - 64\n",
      "        - 64\n",
      "        input_image_size:\n",
      "        - 1024\n",
      "        - 1024\n",
      "        mask_in_chans: 16\n",
      "      mask_decoder:\n",
      "        transformer:\n",
      "          _target_: src.models.segment_anything.modeling.transformer_dev.TwoWayTransformer\n",
      "          depth: 2\n",
      "          embedding_dim: 256\n",
      "          mlp_dim: 2048\n",
      "          num_heads: 8\n",
      "        _target_: src.models.segment_anything.modeling.mask_decoder_dev.MaskDecoder\n",
      "        num_multimask_outputs: 3\n",
      "        transformer_dim: 256\n",
      "        iou_head_depth: 3\n",
      "        iou_head_hidden_dim: 256\n",
      "      _target_: src.models.magic_pen.bisam_diff.BiSamDiff\n",
      "      params:\n",
      "        sam_ckpt_path: ${sam_ckpt_path}\n",
      "        use_weights:\n",
      "        - image_encoder\n",
      "        ft_mode: probing\n",
      "    task_name: ${task_name}\n",
      "    optimizer: ${model.optimizer}\n",
      "    scheduler: ${model.scheduler}\n",
      "sam_name: small\n",
      "sam_ckpt_path: ${paths.sam_ckpt_dir}/sam_vit_b_01ec64.pth\n",
      "sam_enc_arch: vit-b\n",
      "tags:\n",
      "- dev\n",
      "task_name: train_probing_diff\n",
      "callbacks:\n",
      "  model_checkpoint:\n",
      "    _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: epoch_{epoch:03d}\n",
      "    monitor: val/loss\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 1\n",
      "    mode: min\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  early_stopping:\n",
      "    _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "    monitor: val/valBinaryJaccardIndex\n",
      "    min_delta: 0.0\n",
      "    patience: 10\n",
      "    verbose: false\n",
      "    mode: max\n",
      "    strict: true\n",
      "    check_finite: true\n",
      "    stopping_threshold: null\n",
      "    divergence_threshold: null\n",
      "    check_on_train_epoch_end: null\n",
      "  model_summary:\n",
      "    _target_: lightning.pytorch.callbacks.RichModelSummary\n",
      "    max_depth: 1\n",
      "  rich_progress_bar:\n",
      "    _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "  lr_monitor:\n",
      "    _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "    logging_interval: null\n",
      "    log_momentum: false\n",
      "    log_weight_decay: false\n",
      "logger:\n",
      "  tensorboard:\n",
      "    _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger\n",
      "    save_dir: ${paths.output_dir}/tensorboard/\n",
      "    name: null\n",
      "    default_hp_metric: false\n",
      "trainer:\n",
      "  _target_: lightning.pytorch.trainer.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 1\n",
      "  max_epochs: 100\n",
      "  accelerator: cpu\n",
      "  devices: 1\n",
      "  precision: 16\n",
      "  check_val_every_n_epoch: 1\n",
      "  deterministic: false\n",
      "  num_sanity_val_steps: 0\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_PATH}\n",
      "  data_dir: ${oc.env:DATA_PATH}\n",
      "  log_dir: ${oc.env:LOGS_PATH}\n",
      "  output_dir: ${hydra:runtime.output_dir}\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "  sam_ckpt_dir: ${oc.env:CHECKPOINTS_PATH}/sam\n",
      "extras:\n",
      "  ignore_warnings: false\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "train: true\n",
      "test: true\n",
      "ckpt_path: null\n",
      "seed: 66\n",
      "compile: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hydra.core.global_hydra import GlobalHydra\n",
    "GlobalHydra.instance().clear()\n",
    "cfg = load_config()\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6138967f-14f5-4ac6-9120-a0a5d733814d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT VIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 15:42:38,683 - INFO ::  Weights loaded for : ['image_encoder']\n"
     ]
    }
   ],
   "source": [
    "module = hydra.utils.instantiate(cfg.model.instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f3be5-6c02-4fe4-ad2e-e03c851e5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = module.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c76d2-b807-4c63-9c64-b60d437f8e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = hydra.utils.instantiate(cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e301f31e-79ab-4840-a263-24618cb16a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup(stage=\"fit\")\n",
    "train_dloader = data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b07843-22ee-4606-8fe0-58f2d98cdb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06afb570-64a3-41fe-b7b0-9af98f09dc2c",
   "metadata": {},
   "source": [
    "### Load config from run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccb099-7518-45cd-9948-f9ddc24c9c92",
   "metadata": {},
   "source": [
    "Inside a Lightning checkpoint you’ll find:\n",
    "\n",
    "* 16-bit scaling factor (if using 16-bit precision training)\n",
    "* Current epoch\n",
    "* Global step\n",
    "* LightningModule’s state_dict\n",
    "* State of all optimizers\n",
    "* State of all learning rate schedulers\n",
    "* State of all callbacks (for stateful callbacks)\n",
    "* State of datamodule (for stateful datamodules)\n",
    "* The hyperparameters (init arguments) with which the model was created\n",
    "* The hyperparameters (init arguments) with which the datamodule was created \n",
    "* State of Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fabbb4a-32f6-402e-ba89-4e92908407fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.magic_pen.task import MagicPenModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7180e61e-93b7-4523-847a-d67bb83386f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_register_runs_ckpt = {\n",
    "    \"probing_concat\":{\n",
    "        \"baseline\": make_path(\n",
    "            \"2024-08-02_18-31-45/checkpoints/epoch_099.ckpt\", \n",
    "            LOGS_PATH, \n",
    "            \"beta\",\n",
    "            \"beta_probing/levir-cd/vit-b\"\n",
    "        )\n",
    "    }\n",
    "}\n",
    "\n",
    "_register_runs_params = {\n",
    "        \"probing_concat\":{\n",
    "        \"baseline\": make_path(\n",
    "            \"2024-08-02_18-31-45/.hydra/config.yaml\",\n",
    "            LOGS_PATH, \n",
    "            \"beta\",\n",
    "            \"beta_probing/levir-cd/vit-b\"\n",
    "        )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73ff7481-5038-4789-80fa-f762ee58160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"probing_concat\"\n",
    "model_name = \"baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "370ddb12-c154-4ace-80d7-9e75638768fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "def load_yaml(path):\n",
    "    with open(path, 'r') as fp:\n",
    "        return yaml.safe_load(fp) \n",
    "        \n",
    "config = load_yaml(_register_runs_params[model_type][model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faa88c44-2bb8-4601-8cf2-bb9ad7f2f6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'name': 'levir-cd',\n",
       "  '_target_': 'src.data.datamodule.CDDataModule',\n",
       "  'params': {'prompt_type': 'sample',\n",
       "   'n_prompt': 1,\n",
       "   'loc': 'center',\n",
       "   'batch_size': 2,\n",
       "   'num_worker': 4,\n",
       "   'pin_memory': False,\n",
       "   'n_shape': 3}},\n",
       " 'model': {'network': {'image_encoder': {'_target_': 'src.models.segment_anything.modeling.image_encoder_dev.ImageEncoderViT',\n",
       "    'depth': 12,\n",
       "    'embed_dim': 768,\n",
       "    'img_size': 1024,\n",
       "    'mlp_ratio': 4,\n",
       "    'norm_layer': None,\n",
       "    'num_heads': 12,\n",
       "    'patch_size': 16,\n",
       "    'qkv_bias': True,\n",
       "    'use_rel_pos': True,\n",
       "    'global_attn_indexes': [2, 5, 8, 11],\n",
       "    'window_size': 14,\n",
       "    'out_chans': 256},\n",
       "   'prompt_encoder': {'_target_': 'src.models.segment_anything.modeling.prompt_encoder_dev.PromptEncoder',\n",
       "    'embed_dim': 512,\n",
       "    'image_embedding_size': [64, 64],\n",
       "    'input_image_size': [1024, 1024],\n",
       "    'mask_in_chans': 16},\n",
       "   'mask_decoder': {'transformer': {'_target_': 'src.models.segment_anything.modeling.transformer_dev.TwoWayTransformer',\n",
       "     'depth': 2,\n",
       "     'embedding_dim': 512,\n",
       "     'mlp_dim': 2048,\n",
       "     'num_heads': 8},\n",
       "    '_target_': 'src.models.segment_anything.modeling.mask_decoder_dev.MaskDecoder',\n",
       "    'num_multimask_outputs': 3,\n",
       "    'transformer_dim': 512,\n",
       "    'iou_head_depth': 3,\n",
       "    'iou_head_hidden_dim': 256},\n",
       "   '_target_': 'src.models.magic_pen.bisam_concat.BiSamConcat'},\n",
       "  'instance': {'_target_': 'src.models.magic_pen.task.MagicPenModule',\n",
       "   'network': '${model.network}',\n",
       "   'params': {'sam_ckpt_path': '${sam_ckpt_path}',\n",
       "    'use_weights': ['image_encoder'],\n",
       "    'ft_mode': 'probing'}}},\n",
       " 'sam_name': 'small',\n",
       " 'sam_ckpt_path': '${paths.sam_ckpt_dir}/sam_vit_b_01ec64.pth',\n",
       " 'sam_enc_arch': 'vit-b',\n",
       " 'tags': ['dev'],\n",
       " 'task_name': 'beta_probing',\n",
       " 'callbacks': {'model_checkpoint': {'_target_': 'lightning.pytorch.callbacks.ModelCheckpoint',\n",
       "   'dirpath': '${paths.output_dir}/checkpoints',\n",
       "   'filename': 'epoch_{epoch:03d}',\n",
       "   'monitor': 'val/loss',\n",
       "   'verbose': False,\n",
       "   'save_last': True,\n",
       "   'save_top_k': 1,\n",
       "   'mode': 'min',\n",
       "   'auto_insert_metric_name': False,\n",
       "   'save_weights_only': False,\n",
       "   'every_n_train_steps': None,\n",
       "   'train_time_interval': None,\n",
       "   'every_n_epochs': None,\n",
       "   'save_on_train_epoch_end': None},\n",
       "  'rich_progress_bar': {'_target_': 'lightning.pytorch.callbacks.RichProgressBar'}},\n",
       " 'logger': {'tensorboard': {'_target_': 'lightning.pytorch.loggers.tensorboard.TensorBoardLogger',\n",
       "   'save_dir': '${paths.output_dir}/tensorboard/',\n",
       "   'name': None,\n",
       "   'default_hp_metric': False}},\n",
       " 'trainer': {'_target_': 'lightning.pytorch.trainer.Trainer',\n",
       "  'default_root_dir': '${paths.output_dir}',\n",
       "  'min_epochs': 1,\n",
       "  'max_epochs': 100,\n",
       "  'accelerator': 'gpu',\n",
       "  'devices': 4,\n",
       "  'check_val_every_n_epoch': 1,\n",
       "  'deterministic': False,\n",
       "  'num_sanity_val_steps': 0,\n",
       "  'strategy': 'ddp',\n",
       "  'num_nodes': 2,\n",
       "  'sync_batchnorm': True},\n",
       " 'paths': {'root_dir': '${oc.env:PROJECT_PATH}',\n",
       "  'data_dir': '${oc.env:DATA_PATH}',\n",
       "  'log_dir': '${oc.env:LOGS_PATH}',\n",
       "  'output_dir': '${hydra:runtime.output_dir}',\n",
       "  'work_dir': '${hydra:runtime.cwd}',\n",
       "  'sam_ckpt_dir': '${oc.env:CHECKPOINTS_PATH}/sam'},\n",
       " 'extras': {'ignore_warnings': False,\n",
       "  'enforce_tags': True,\n",
       "  'print_config': True},\n",
       " 'train': True,\n",
       " 'test': True,\n",
       " 'ckpt_path': None,\n",
       " 'seed': 66}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24e7c70f-0552-4e0d-b240-0d1796c1e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = config[\"model\"][\"instance\"][\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1d7fbfc-2d6c-42b3-95c7-13a105acffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del params[\"sam_ckpt_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95ac723d-4114-4468-b7b2-40fdab8ced29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "764d5d33-5e66-43b8-8ba9-3a993ebddbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[14].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f85280bf-dbfc-4101-885a-c15ac0f21e31",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide sam checkpoint",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mMagicPenModule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_register_runs_ckpt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mp/lib/python3.10/site-packages/lightning/pytorch/utilities/model_helpers.py:125\u001b[0m, in \u001b[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be called on an instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mp/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1581\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1500\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \n\u001b[1;32m   1580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1581\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/miniforge3/envs/mp/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:91\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[0;32m---> 91\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
      "File \u001b[0;32m~/miniforge3/envs/mp/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:158\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cls_spec\u001b[38;5;241m.\u001b[39mvarkw:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# filter kwargs according to class init unless it allows any argument via kwargs\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     _cls_kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _cls_kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m cls_init_args_name}\n\u001b[0;32m--> 158\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_cls_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, pl\u001b[38;5;241m.\u001b[39mLightningDataModule):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m checkpoint:\n",
      "File \u001b[0;32m~/projects/stage_stylo_magique_2024/src/models/magic_pen/task.py:47\u001b[0m, in \u001b[0;36mMagicPenModule.__init__\u001b[0;34m(self, network, params)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# let's prevent checkpoint forgetting\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msam_ckpt_path\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide sam checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mft_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide ft mode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide sam checkpoint"
     ]
    }
   ],
   "source": [
    "module = MagicPenModule.load_from_checkpoint(\n",
    "    _register_runs_ckpt[model_type][model_name],\n",
    "    params=params,\n",
    "    network = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd7689-3140-43b5-9106-c5088903d7e2",
   "metadata": {},
   "source": [
    "### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d131c7-399e-429f-9f89-1c872c3e33af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
