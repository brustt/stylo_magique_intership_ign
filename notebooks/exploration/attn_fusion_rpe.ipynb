{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3453a5ec-c835-4132-9051-c233b7798367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env variables\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# set local dir logs based on date _${now:%Y-%m-%d}_${now:%H-%M-%S}\n",
    "os.environ[\"SLURM_JOB_ID\"] = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bfbffa1-b30d-4234-b731-318eb3cded14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import torch\n",
    "from src.commons.constants import PROJECT_PATH\n",
    "from omegaconf import DictConfig, OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e200383-e172-4f0f-864e-c9c36c76ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    # Initialize the Hydra configuration\n",
    "    hydra.initialize(config_path=\"../configs\", version_base=None)\n",
    "    \n",
    "    # Compose the configuration with the desired environment override\n",
    "    cfg = hydra.compose(\n",
    "        config_name=\"train\", \n",
    "        overrides=[\"experiment=adapter_concat\", \n",
    "                   \"sam_type=small\", \n",
    "                   \"data=levir-cd\",\n",
    "                   \"data.params.batch_size=1\"\n",
    "                  ])\n",
    "    \n",
    "    return cfg\n",
    "\n",
    "def get_dloader(mode: str, dmodule):\n",
    "\n",
    "    def wrap_mode(mode):\n",
    "        if mode == \"train\":\n",
    "            return \"fit\"\n",
    "        return mode\n",
    "    if not dmodule.ds_dict_type:\n",
    "        mode_ = wrap_mode(mode)\n",
    "        dmodule.setup(mode_)\n",
    "    factory_dl = {\n",
    "        \"train\": dmodule.train_dataloader,\n",
    "        \"val\": dmodule.val_dataloader,\n",
    "        \"test\": dmodule.test_dataloader,\n",
    "    }\n",
    "    return factory_dl[mode]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0edde6ea-486a-4949-b28a-4265daf7913c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hydra.core.global_hydra import GlobalHydra\n",
    "GlobalHydra.instance().clear()\n",
    "cfg = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4fc058c-9c22-49f3-a490-a0d809dd466a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/data/usr/mdizier/stylo_magique/checkpoints/sam/sam_vit_b_01ec64.pth'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.sam_ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ab84aa-054f-4c12-93f0-7617640473c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT ADAPTER VIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 20:45:18,587 - INFO ::  Weights loaded for : ['image_encoder']\n"
     ]
    }
   ],
   "source": [
    "module = hydra.utils.instantiate(cfg.model.instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dae739e0-7e8a-4e49-8876-00a395982d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = hydra.utils.instantiate(cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09e432f4-b89d-439e-afed-7f7080b28928",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = get_dloader(\"test\", data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816adbef-72c0-45de-9855-df8d0316cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfcdd3f0-dd4a-494d-8b23-a6a3f75293e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = module.model(batch, multimask_output=False)\n",
    "preds = preds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cb40b31-9ccc-43e9-a4dd-940a46a334db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1024])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61ff7b6a-4001-4fdd-a433-c500dd3f8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_embeddings = module.model.image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "216aa3ab-0d87-450d-8221-0af29d5db6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand((2, 2, 256, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe0b4228-d064-43a0-8b36-3682118b5d8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39mmax_pool2d(t, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "res = F.max_pool2d(t, kernel_size=4, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "361a7f80-2ecc-4313-9890-80c929c95c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 32, 32])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c075716d-1c04-43a4-98c5-06e7bedc71a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 32, 32])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=2, stride=2)\n",
    "ld(t.view(-1, *t.shape[2:])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d94a50e6-3fa5-4827-86c4-c5bae0203faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=2, stride=2)\n",
    "res2 = l(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0fb351-a3d2-4307-8216-a564a0f10eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08feced-5375-422b-9c4c-cac1f2aa5fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4d85e9a-64bd-404e-866c-61fbfba0885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7410e018-9a75-409e-9859-3f00b9def1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.rand(4096, 1, 256)\n",
    "k = torch.rand(4096, 2, 256)\n",
    "v = torch.rand(4096, 2, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535c09cf-12df-4726-a199-a6b7bb0d8fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 2, 256])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb11f742-686c-4c4c-932e-86497fb05c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 1, 256])\n",
      "torch.Size([4096, 256, 2])\n"
     ]
    }
   ],
   "source": [
    "print(q.shape)\n",
    "print(k.transpose(-2, -1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27b84963-c55f-4e84-afce-87e3f389cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = (q @ k.transpose(-2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c67025d5-8fa2-429e-beb8-00af0b46ab66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ad35005",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sqrt(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: sqrt(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "torch.sqrt([5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a41ff6-6269-451d-92f2-f0c0d57bcba5",
   "metadata": {},
   "source": [
    "On veut 4096 x 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a795f1a-c638-49ce-86af-5dfb48b2a8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 1, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn2 = (attn @ v)\n",
    "attn2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6330f8e-3d37-4b72-88ef-35203fc6a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 256, 2, 64, 64)\n",
    "B, C, T, H, W = x.shape\n",
    "\n",
    "# flat spatial dimensions\n",
    "x = x.permute(0, 3, 4, 2, 1).view(B, -1, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c27beb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096, 2, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac0a479a-6022-4cb7-8258-f6396d30eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 256\n",
    "num_patches = 64 * 64\n",
    "qkv_bias=False\n",
    "\n",
    "wk = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "wv = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "wq = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "# self.q_learned = nn.Parameter(torch.zeros(1, 1, dim))\n",
    "\n",
    "\n",
    "q_learned = nn.Parameter(torch.zeros(1, num_patches, dim))\n",
    "# self.pos_embed = nn.Parameter(torch.zeros(1, self.num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb235ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_learned.expand(B, -1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cac41ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096, 2, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wk(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "472ac79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q torch.Size([2, 4096, 1, 256])\n",
      "k torch.Size([2, 4096, 2, 256])\n",
      "v torch.Size([2, 4096, 2, 256])\n",
      "attn torch.Size([2, 4096, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "B, N, T, C = x.shape\n",
    "q = q_learned.expand(B, -1, -1).unsqueeze(2)\n",
    "k = wk(x)\n",
    "v = wv(x)\n",
    "\n",
    "print(\"q\", q.shape)\n",
    "print(\"k\", k.shape)\n",
    "print(\"v\", v.shape)\n",
    "\n",
    "# attn torch.Size([B, 8, 4096, 4096])\n",
    "attn = (q @ k.transpose(-2, -1)) \n",
    "print(\"attn\", attn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "753d4f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x cut torch.Size([2, 4096, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# attn = attn.softmax(dim=-1)\n",
    "# attn = self.attn_drop(attn)\n",
    "\n",
    "x = (attn @ v).transpose(1, 2).reshape(B, num_patches, C)\n",
    "# x = self.proj(x)\n",
    "# x = self.proj_drop(x)\n",
    "# print(\"xb\", x.shape)\n",
    "# x = x[:,  :self.num_patches_original, :]\n",
    "print(\"x cut\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95deeac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5594d852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a908e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d8d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f152ef89-e108-40d5-b614-e1b44482f55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MDizier/projects/stage_stylo_magique_2024/src/models/commons/rpe/irpe.py:14: UserWarning: \u001b[91m[WARNING] The module `rpe_ops` is not built. For better training performance, please build `rpe_ops`.\u001b[00m\n",
      "  warnings.warn(RED_STR.format(\"[WARNING] The module `rpe_ops` is not built. \\\n"
     ]
    }
   ],
   "source": [
    "from src.models.commons.rpe.irpe import build_rpe, get_rpe_config\n",
    "num_heads=8\n",
    "head_dim = dim // num_heads\n",
    "rpe_config = get_rpe_config(\n",
    "    ratio=1.9,\n",
    "    method=\"euc\",\n",
    "    mode='ctx',\n",
    "    shared_head=True,\n",
    "    skip=0,\n",
    "    rpe_on='k',# do we need more ? \n",
    ")\n",
    "rpe_q, rpe_k, rpe_v = build_rpe(rpe_config,\n",
    "                               head_dim=head_dim,\n",
    "                               num_heads=num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d00cfebe-7d2c-42af-88cf-54d670241964",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, N, T,C = x.shape\n",
    "num_patches = N // T\n",
    "q_ = q_learned.expand(B, N, -1).reshape(B, N, num_heads, C // num_heads).permute(0, 2, 1, 3)\n",
    "\n",
    "# print(self.wq(x).shape)\n",
    "q = wq(x).reshape(B, N, T, num_heads, C // num_heads).permute(0, 3, 1, 2, 4)\n",
    "# BNC -> BNH(C/H) -> BHN(C/H)\n",
    "k = wk(x).reshape(B, N, T, num_heads, C // num_heads).permute(0, 3, 1, 2, 4)\n",
    "# BNC -> BNH(C/H) -> BHN(C/H)\n",
    "v = wv(x).reshape(B, N, T, num_heads, C // num_heads).permute(0, 3, 1, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eec27874-fd13-4a61-81c9-213a7fec57d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 4096, 32])\n",
      "torch.Size([2, 8, 32, 4096])\n"
     ]
    }
   ],
   "source": [
    "xx = torch.rand(B, 4096, 256)\n",
    "kk = wk(xx).reshape(B, N, num_heads, C // num_heads).permute(0, 2, 1, 3)\n",
    "print(kk.shape)\n",
    "print(kk.transpose(-2, -1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf211288-a340-4d73-ba45-fe6e0cdf3609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d939301-70db-463d-a8dc-f192a63b438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4096, 1, 8, 32])\n",
      "torch.Size([2, 4096, 2, 8, 32])\n"
     ]
    }
   ],
   "source": [
    "q1 = q_learned.expand(B, N, -1).unsqueeze(2).reshape(B, N, 1, num_heads, C // num_heads)\n",
    "k1 = wk(x).reshape(B, N, T, num_heads, C // num_heads)\n",
    "print(q1.shape)\n",
    "print(k1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18caee7f-9671-462a-b1bd-8eb241d31a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1 = q1.permute(0, 3, 1, 1, 4)\n",
    "# k1 = k1.permute(0, 3, 3, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaa997e1-fe4c-46ff-89ee-c0d88752c8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096, 2, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf10f037-8358-4956-a5b9-32371edf4240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096, 1, 256])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d38baba1-39ce-49d3-8b8c-c48e072fb549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096, 2, 32, 8])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1.transpose(-2, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4688d787-786f-4d55-8e30-6bf01d822bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = (q1 @ k1.transpose(-2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ec79cb8-f2cd-494f-9252-422c17f8d06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096, 2, 8, 8])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "562c737f-196c-40ac-ad95-ca33e9c13bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096, 1, 256])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6374a16c-acb7-4223-b6b5-c9c07d5a2c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096, 1, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given tensors\n",
    "A = torch.randn(2, 4096, 1, 8, 32)  # Tensor A\n",
    "B = torch.randn(2, 4096, 2, 8, 32)  # Tensor B\n",
    "\n",
    "# Step 1: Perform the dot product along the last two dimensions (dim=-2 and dim=-1)\n",
    "# We use torch.einsum for a flexible dot product operation.\n",
    "# \"ijklm,ijnlm->ijkn\" indicates the reduction of the last two dimensions.\n",
    "\n",
    "result = torch.einsum('ijklm,ijnlm->ijkn', A, B)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7860cf-b2e3-4bb1-908c-028a3aaccb35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae216d21-75f1-46a7-9395-cae40314539e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02794c67-4ed3-4a15-b993-9960082bc365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 4096, 32])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq = q1.reshape(2, 8, 4096, 1, 256 // 8).squeeze(3)\n",
    "qq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ae09d4a-38c1-4ecd-8f2e-d9410a42ae20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full rpe k torch.Size([2, 32768, 1, 1])\n",
      "rpe k extend torch.Size([2, 32768, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "n_modalities = 2\n",
    "print(\"full rpe k\",  rpe_k(q1).shape)\n",
    "print(\"rpe k extend\", rpe_k(q1).repeat(1, 1, 1, n_modalities).shape)\n",
    "repq1 = rpe_k(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a796b4b4-4e13-42af-aea8-3cd73c710d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 4096, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repq1.reshape(2, 8, 32768 // 8, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4d8131c-b8a8-47e9-9752-64ad9020b119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x irpe torch.Size([2, 8, 4096, 32])\n",
      "L 4096\n",
      "skip 0\n",
      "7\n",
      "7\n",
      "full rpe k torch.Size([2, 8, 4096, 4096])\n",
      "rpe k extend torch.Size([2, 8, 4096, 8192])\n"
     ]
    }
   ],
   "source": [
    "n_modalities = 2\n",
    "print(\"full rpe k\",  rpe_k(qq).shape)\n",
    "print(\"rpe k extend\", rpe_k(qq).repeat(1, 1, 1, n_modalities).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3190cba9-cdb4-4450-8b9d-0470b890ebee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32768/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3840e81f-9927-4ee1-bd8d-d0db2c93debd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a86c2-d001-45fe-8819-6c721e509830",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn2 = (attn @ v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6726d6e0-e9ba-41e3-be50-85a2448a40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69099ec6-afbe-4dc1-85cf-2e19e71924d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f15dff-10ad-448d-a957-67cb3fb7522a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c918ca-bcfe-4d39-8f87-f6d0b0d24d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61be6a-e0ed-4ffa-8dfd-6863479b471b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d8ab9f5-d4ab-45fc-b91b-632418da6f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "dim=256\n",
    "num_patches=8192\n",
    "num_heads=8\n",
    "x = torch.rand((2, 8192, 256))\n",
    "q_learned = nn.Parameter(torch.zeros(1, 1, dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e71d942-dab6-4b88-bc14-c74ab435c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, N, C = x.shape\n",
    "# B1C -> B1H(C/H) -> BH1(C/H)\n",
    "q_ = q_learned.expand(B, num_patches, -1)\n",
    "q = q_.reshape(B, num_patches, num_heads, C // num_heads).permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61bd37a1-0282-4be2-9ef0-0ab84c5ff8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 8192, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3de7bb2-0b27-431c-846a-79e483bf2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b11c998-10fe-4b84-b8a2-79c90eff1fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 8192])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2481ea0c-92f1-46ce-bd59-c3e344b69fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 8281])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "pa = 91*91 - x.shape[-1]\n",
    "x = F.pad(x, (0, int(pa)))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "324e5d1a-18c0-4851-9a7c-4bfdba6a4a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8190"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1b01eaf-519d-4aad-8a93-2158ecb38770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8281"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "91**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9562620-eed5-43bd-b060-3bf0fa85fe76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.permute(0, 2, 1)[0, 8280, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7eb60a-4cb1-402d-a203-10200f68cd14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp-3.10",
   "language": "python",
   "name": "mp_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
